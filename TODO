import static com.google.protobuf.TensorContentEncoder.toStringTensorContent; // TODO prehodit

    // TODO vyhodit qmlContext
    public <T extends TFType, NTType> TF<T, NTType> makeFromTemplate(TF<T, NTType> node, QMLContext qmlContext) {

Engine musi byt closeable

TensorflowEngine -> TFEngine

divide casts
testy pro reduceMean (ints)
placeholders
gradients_impl.py:600

vyzkouset inicializaci tri promennych
check driv - java.lang.IllegalArgumentException: Node 'difference' is not unique
sladit CSVClasspathResource a ClasspathResource
TemplateProcessor ?
lazy loading pro template telo
http://www.baeldung.com/convert-input-stream-to-array-of-bytes
http://www.baeldung.com/java-io-conversions
https://blog.gdeltproject.org/a-compilation-of-gdelt-bigquery-demos/
https://towardsdatascience.com/eager-execution-tensorflow-8042128ca7be - tensorflow 1.7
https://dev.to/shamdasani/build-a-flexible-neural-network-with-backpropagation-in-python
https://codesachin.wordpress.com/2015/12/06/backpropagation-for-dummies/
https://towardsdatascience.com/learning-backpropagation-from-geoffrey-hinton-619027613f0
http://www.dummies.com/education/math/calculus/how-to-use-the-chain-rule-to-find-the-derivative-of-nested-functions/
http://www.dummies.com/education/math/calculus/how-to-find-a-functions-derivative-by-using-the-chain-rule/

tensorboard: https://medium.com/@anthony_sarkis/tensorboard-quick-start-in-5-minutes-e3ec69f673af
  tensorboard --logdir /tmp/ex03tb

http://asm.ow2.org/doc/developer-guide.html
javap -l target/test-classes/org/superbiz/builder/UseCase01Test.class
javap -l -c -s -verbose target/test-classes/org/superbiz/builder/UseCase01Test.class

protoc --java_out=src/main/java tensorflow/core/framework/graph.proto

- https://github.com/tensorflow/models/blob/master/samples/languages/java/object_detection/src/main/java/DetectObjects.java
- https://dinantdatascientist.blogspot.de/2018/02/kaggle-tensorflow-speech-recognition.html
- F -> C https://towardsdatascience.com/machine-learning-from-scratch-part-4-10117c005a28



reduceMeanNode:  [<tf.Tensor 'gradients/Fill:0' shape=() dtype=float32>]
squareNode:  [<tf.Tensor 'gradients/reduceMeanNode_grad/truediv:0' shape=(100,) dtype=float32>]
sub:  [<tf.Tensor 'gradients/squareNode_grad/Mul_1:0' shape=(100,) dtype=float32>]
add_1:  [<tf.Tensor 'gradients/squareNode_grad/Mul_1:0' shape=(100,) dtype=float32>]
sub/y:  [[<tf.Tensor 'gradients/sub_grad/Neg:0' shape=(100,) dtype=float32>]]
add:  [<tf.Tensor 'gradients/add_1_grad/Reshape:0' shape=(100,) dtype=float32>]
c/read:  [<tf.Tensor 'gradients/add_1_grad/Reshape_1:0' shape=() dtype=float32>]
mul:  [<tf.Tensor 'gradients/add_grad/Reshape:0' shape=(100,) dtype=float32>]
b/read:  [<tf.Tensor 'gradients/add_grad/Reshape_1:0' shape=() dtype=float32>]
c:  [<tf.Tensor 'gradients/add_1_grad/Reshape_1:0' shape=() dtype=float32>]
a/read:  [<tf.Tensor 'gradients/mul_grad/Reshape:0' shape=() dtype=float32>]
mul/y:  [[<tf.Tensor 'gradients/mul_grad/Reshape_1:0' shape=(100,) dtype=float32>]]
b:  [<tf.Tensor 'gradients/add_grad/Reshape_1:0' shape=() dtype=float32>]
a:  [<tf.Tensor 'gradients/mul_grad/Reshape:0' shape=() dtype=float32>]





2 promenny - gradient:
[[-3.6977046, -5.911225]]


reduceMeanNode:  [<tf.Tensor 'gradients/Fill:0' shape=() dtype=float32>]
squareNode:  [<tf.Tensor 'gradients/reduceMeanNode_grad/truediv:0' shape=(100,) dtype=float32>]
sub:  [<tf.Tensor 'gradients/squareNode_grad/Mul_1:0' shape=(100,) dtype=float32>]
add:  [<tf.Tensor 'gradients/squareNode_grad/Mul_1:0' shape=(100,) dtype=float32>]
sub/y:  [[<tf.Tensor 'gradients/sub_grad/Neg:0' shape=(100,) dtype=float32>]]
mul:  [<tf.Tensor 'gradients/add_grad/Reshape:0' shape=(100,) dtype=float32>]
b/read:  [<tf.Tensor 'gradients/add_grad/Reshape_1:0' shape=() dtype=float32>]
a/read:  [<tf.Tensor 'gradients/mul_grad/Reshape:0' shape=() dtype=float32>]
mul/y:  [[<tf.Tensor 'gradients/mul_grad/Reshape_1:0' shape=(100,) dtype=float32>]]
b:  [<tf.Tensor 'gradients/add_grad/Reshape_1:0' shape=() dtype=float32>]
a:  [<tf.Tensor 'gradients/mul_grad/Reshape:0' shape=() dtype=float32>]


gradients/reduceMeanNode_grad/truediv:0: [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01
 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01
 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01
 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01
 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01
 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01
 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01
 0.01 0.01]


gradients/squareNode_grad/Mul_1:0: [-0.05783287 -0.05510806 -0.04846408 -0.05195377 -0.07349733 -0.03809765
 -0.05119103 -0.07051501 -0.05826342 -0.07432117 -0.07483348 -0.05072181
 -0.04337982 -0.07926709 -0.07169849 -0.06129011 -0.05157378 -0.0689927
 -0.07347802 -0.07580078 -0.05345382 -0.06919668 -0.0703302  -0.05907134
 -0.07277023 -0.04749179 -0.06173897 -0.05361338 -0.03905983 -0.06659739
 -0.0588707  -0.05706827 -0.05195614 -0.04780582 -0.0632581  -0.06270552
 -0.0603166  -0.04968087 -0.0664601  -0.06152668 -0.05725225 -0.07235388
 -0.03951639 -0.06045339 -0.0622522  -0.06773173 -0.05114728 -0.0514986
 -0.05939518 -0.07070386 -0.03828399 -0.05814389 -0.06293643 -0.04796091
 -0.05158721 -0.05227835 -0.05213241 -0.06503021 -0.06607974 -0.0628268
 -0.0633084  -0.06746357 -0.0602571  -0.04844737 -0.05572554 -0.06225762
 -0.05709356 -0.06577551 -0.05878595 -0.07307879 -0.07190583 -0.04665817
 -0.04907468 -0.06356726 -0.04385729 -0.06809382 -0.04925543 -0.07191908
 -0.06790006 -0.04740337 -0.06708585 -0.05728017 -0.07272302 -0.07044088
 -0.05813399 -0.06593242 -0.07517847 -0.04914192 -0.03332053 -0.0659048
 -0.03946535 -0.0698402  -0.04699596 -0.07423275 -0.05763786 -0.03907949
 -0.07445294 -0.05286241 -0.0551656  -0.04170418]


gradients/squareNode_grad/Mul_1:0: [-0.05783287 -0.05510806 -0.04846408 -0.05195377 -0.07349733 -0.03809765
 -0.05119103 -0.07051501 -0.05826342 -0.07432117 -0.07483348 -0.05072181
 -0.04337982 -0.07926709 -0.07169849 -0.06129011 -0.05157378 -0.0689927
 -0.07347802 -0.07580078 -0.05345382 -0.06919668 -0.0703302  -0.05907134
 -0.07277023 -0.04749179 -0.06173897 -0.05361338 -0.03905983 -0.06659739
 -0.0588707  -0.05706827 -0.05195614 -0.04780582 -0.0632581  -0.06270552
 -0.0603166  -0.04968087 -0.0664601  -0.06152668 -0.05725225 -0.07235388
 -0.03951639 -0.06045339 -0.0622522  -0.06773173 -0.05114728 -0.0514986
 -0.05939518 -0.07070386 -0.03828399 -0.05814389 -0.06293643 -0.04796091
 -0.05158721 -0.05227835 -0.05213241 -0.06503021 -0.06607974 -0.0628268
 -0.0633084  -0.06746357 -0.0602571  -0.04844737 -0.05572554 -0.06225762
 -0.05709356 -0.06577551 -0.05878595 -0.07307879 -0.07190583 -0.04665817
 -0.04907468 -0.06356726 -0.04385729 -0.06809382 -0.04925543 -0.07191908
 -0.06790006 -0.04740337 -0.06708585 -0.05728017 -0.07272302 -0.07044088
 -0.05813399 -0.06593242 -0.07517847 -0.04914192 -0.03332053 -0.0659048
 -0.03946535 -0.0698402  -0.04699596 -0.07423275 -0.05763786 -0.03907949
 -0.07445294 -0.05286241 -0.0551656  -0.04170418]


gradients/sub_grad/Neg:0: [0.05783287 0.05510806 0.04846408 0.05195377 0.07349733 0.03809765
 0.05119103 0.07051501 0.05826342 0.07432117 0.07483348 0.05072181
 0.04337982 0.07926709 0.07169849 0.06129011 0.05157378 0.0689927
 0.07347802 0.07580078 0.05345382 0.06919668 0.0703302  0.05907134
 0.07277023 0.04749179 0.06173897 0.05361338 0.03905983 0.06659739
 0.0588707  0.05706827 0.05195614 0.04780582 0.0632581  0.06270552
 0.0603166  0.04968087 0.0664601  0.06152668 0.05725225 0.07235388
 0.03951639 0.06045339 0.0622522  0.06773173 0.05114728 0.0514986
 0.05939518 0.07070386 0.03828399 0.05814389 0.06293643 0.04796091
 0.05158721 0.05227835 0.05213241 0.06503021 0.06607974 0.0628268
 0.0633084  0.06746357 0.0602571  0.04844737 0.05572554 0.06225762
 0.05709356 0.06577551 0.05878595 0.07307879 0.07190583 0.04665817
 0.04907468 0.06356726 0.04385729 0.06809382 0.04925543 0.07191908
 0.06790006 0.04740337 0.06708585 0.05728017 0.07272302 0.07044088
 0.05813399 0.06593242 0.07517847 0.04914192 0.03332053 0.0659048
 0.03946535 0.0698402  0.04699596 0.07423275 0.05763786 0.03907949
 0.07445294 0.05286241 0.0551656  0.04170418]


gradients/add_grad/Reshape:0: [-0.05783287 -0.05510806 -0.04846408 -0.05195377 -0.07349733 -0.03809765
 -0.05119103 -0.07051501 -0.05826342 -0.07432117 -0.07483348 -0.05072181
 -0.04337982 -0.07926709 -0.07169849 -0.06129011 -0.05157378 -0.0689927
 -0.07347802 -0.07580078 -0.05345382 -0.06919668 -0.0703302  -0.05907134
 -0.07277023 -0.04749179 -0.06173897 -0.05361338 -0.03905983 -0.06659739
 -0.0588707  -0.05706827 -0.05195614 -0.04780582 -0.0632581  -0.06270552
 -0.0603166  -0.04968087 -0.0664601  -0.06152668 -0.05725225 -0.07235388
 -0.03951639 -0.06045339 -0.0622522  -0.06773173 -0.05114728 -0.0514986
 -0.05939518 -0.07070386 -0.03828399 -0.05814389 -0.06293643 -0.04796091
 -0.05158721 -0.05227835 -0.05213241 -0.06503021 -0.06607974 -0.0628268
 -0.0633084  -0.06746357 -0.0602571  -0.04844737 -0.05572554 -0.06225762
 -0.05709356 -0.06577551 -0.05878595 -0.07307879 -0.07190583 -0.04665817
 -0.04907468 -0.06356726 -0.04385729 -0.06809382 -0.04925543 -0.07191908
 -0.06790006 -0.04740337 -0.06708585 -0.05728017 -0.07272302 -0.07044088
 -0.05813399 -0.06593242 -0.07517847 -0.04914192 -0.03332053 -0.0659048
 -0.03946535 -0.0698402  -0.04699596 -0.07423275 -0.05763786 -0.03907949
 -0.07445294 -0.05286241 -0.0551656  -0.04170418]


gradients/add_grad/Reshape_1:0: -5.91122484207


gradients/mul_grad/Reshape:0: -3.6977045536


gradients/mul_grad/Reshape_1:0: [-0.05783287 -0.05510806 -0.04846408 -0.05195377 -0.07349733 -0.03809765
 -0.05119103 -0.07051501 -0.05826342 -0.07432117 -0.07483348 -0.05072181
 -0.04337982 -0.07926709 -0.07169849 -0.06129011 -0.05157378 -0.0689927
 -0.07347802 -0.07580078 -0.05345382 -0.06919668 -0.0703302  -0.05907134
 -0.07277023 -0.04749179 -0.06173897 -0.05361338 -0.03905983 -0.06659739
 -0.0588707  -0.05706827 -0.05195614 -0.04780582 -0.0632581  -0.06270552
 -0.0603166  -0.04968087 -0.0664601  -0.06152668 -0.05725225 -0.07235388
 -0.03951639 -0.06045339 -0.0622522  -0.06773173 -0.05114728 -0.0514986
 -0.05939518 -0.07070386 -0.03828399 -0.05814389 -0.06293643 -0.04796091
 -0.05158721 -0.05227835 -0.05213241 -0.06503021 -0.06607974 -0.0628268
 -0.0633084  -0.06746357 -0.0602571  -0.04844737 -0.05572554 -0.06225762
 -0.05709356 -0.06577551 -0.05878595 -0.07307879 -0.07190583 -0.04665817
 -0.04907468 -0.06356726 -0.04385729 -0.06809382 -0.04925543 -0.07191908
 -0.06790006 -0.04740337 -0.06708585 -0.05728017 -0.07272302 -0.07044088
 -0.05813399 -0.06593242 -0.07517847 -0.04914192 -0.03332053 -0.0659048
 -0.03946535 -0.0698402  -0.04699596 -0.07423275 -0.05763786 -0.03907949
 -0.07445294 -0.05286241 -0.0551656  -0.04170418]


gradients/add_grad/Reshape_1:0: -5.91122484207


gradients/mul_grad/Reshape:0: -3.6977045536
